{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCPWJN8cqAx-",
        "outputId": "6e5f3df6-213d-43be-a592-79b7267b9067"
      },
      "outputs": [],
      "source": [
        "#!pip install torchtext torchdata datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "x5sF6gJDIA_t"
      },
      "outputs": [],
      "source": [
        "# # Using TPU\n",
        "# !pip install torchtext torchdata cloud-tpu-client==0.10 torch==1.12.1 https://storage.googleapis.com/tpu-pytorch/wheels/colab/torch_xla-1.12-cp37-cp37m-linux_x86_64.whl\n",
        "# import torch_xla\n",
        "# import torch_xla.core.xla_model as xm\n",
        "# device = xm.xla_device()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-zj8XSYp7LV",
        "outputId": "0a008207-03de-4169-fce9-ca3e0fa86931"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "selected device: cuda:0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Reusing dataset imdb (C:\\Users\\sms20\\.cache\\huggingface\\datasets\\imdb\\plain_text\\1.0.0\\2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d3385674bb1549a68a3bbc89ff3ed8a8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7e57a3a259fa4b2f91efb30adc374f6b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0ex [00:00, ?ex/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bf8b4817e0e84efb933141ea35a73eb6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0ex [00:00, ?ex/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset({\n",
            "    features: ['text', 'label', 'tokens'],\n",
            "    num_rows: 25000\n",
            "}) Dataset({\n",
            "    features: ['text', 'label', 'tokens'],\n",
            "    num_rows: 25000\n",
            "})\n",
            "[165, 9, 43, 491]\n"
          ]
        }
      ],
      "source": [
        "import functools\n",
        "import datasets\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import time\n",
        "from torchtext.vocab import Vocab\n",
        "\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "\n",
        "# import spacy\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# spacy_en = spacy.load('en_core_web_md')\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'selected device: {device}')\n",
        "tokenizer = get_tokenizer('spacy', 'en_core_web_md')\n",
        "train_data, test_data = datasets.load_dataset('imdb', split=['train', 'test'])\n",
        "\n",
        "\n",
        "def tokenize_data(example, tokenizer):\n",
        "    tokens = {'tokens': tokenizer(example['text'])}\n",
        "    return tokens\n",
        "\n",
        "\n",
        "# def tokenize(example):\n",
        "#     tokens = {'tokens': spacy_en.tokenizer(example['text']) for e in example}\n",
        "#     return tokens\n",
        "\n",
        "train_data = train_data.map(tokenize_data, fn_kwargs={'tokenizer': tokenizer})\n",
        "test_data = test_data.map(tokenize_data, fn_kwargs={'tokenizer': tokenizer})\n",
        "print(train_data, test_data)\n",
        "\n",
        "test_size = 0.2\n",
        "train_valid_data = train_data.train_test_split(test_size=test_size)\n",
        "train_data = train_valid_data['train']\n",
        "valid_data = train_valid_data['test']\n",
        "\n",
        "min_freq = 5\n",
        "special_tokens = ['<unk>', '<pad>']\n",
        "\n",
        "vocab = build_vocab_from_iterator(\n",
        "    train_data['tokens'], min_freq=min_freq, specials=special_tokens\n",
        ")\n",
        "\n",
        "print(vocab(['here', 'is', 'an', 'example']))\n",
        "\n",
        "unk_index = vocab['<unk>']\n",
        "pad_index = vocab['<pad>']\n",
        "vocab.set_default_index(unk_index)\n",
        "\n",
        "\n",
        "text_pipeline = lambda x: vocab(tokenize_data(x))\n",
        "label_pipeline = lambda x: 1 if x == 'pos' else 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def numericalize_data(example, vocab):\n",
        "    ids = {'ids': [vocab[token] for token in example['tokens']]}\n",
        "    return ids\n",
        "\n",
        "train_data.set_format(type='torch', columns=['ids', 'label'])\n",
        "valid_data.set_format(type='torch', columns=['ids', 'label'])\n",
        "test_data.set_format(type='torch', columns=['ids', 'label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5SIprT1sKg-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0JtWY6Fug5m"
      },
      "outputs": [],
      "source": [
        "# Refill Generators & Put in the DataLoader\n",
        "train_iter, valid_iter, test_iter = train_data, valid_data, test_data\n",
        "BATCH_SIZE = 100\n",
        "\n",
        "\n",
        "train_dataloader, valid_dataloader, test_dataloader = (\n",
        "    DataLoader(\n",
        "        train_iter, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
        "    ),\n",
        "    DataLoader(\n",
        "        valid_iter, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
        "    ),\n",
        "    DataLoader(\n",
        "        test_iter, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDxQRnwZw7Ee"
      },
      "outputs": [],
      "source": [
        "class TextClassificationModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, num_class):\n",
        "        super(TextClassificationModel, self).__init__()\n",
        "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
        "        self.fc = nn.Linear(embed_dim, num_class)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.5\n",
        "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.bias.data.zero_()\n",
        "\n",
        "    def forward(self, text, offsets):\n",
        "        embedded = self.embedding(text, offsets)\n",
        "        return self.fc(embedded)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QOYB43CT5O53"
      },
      "outputs": [],
      "source": [
        "train_iter = AG_NEWS(split='train')\n",
        "num_class = len(set([label for (label, text) in train_iter]))\n",
        "vocab_size = len(vocab)\n",
        "emsize = 64\n",
        "model = TextClassificationModel(vocab_size, emsize, num_class).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W62DZhFC8ND2"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data.dataset import random_split\n",
        "from torchtext.data.functional import to_map_style_dataset\n",
        "\n",
        "# Hyperparameters\n",
        "EPOCHS = 12  # epoch\n",
        "LR = 4.8  # learning rate\n",
        "# BATCH_SIZE = 64\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
        "total_accu = None\n",
        "train_iter, test_iter = AG_NEWS(split=('train', 'test'))\n",
        "\n",
        "train_dataset = to_map_style_dataset(train_iter)\n",
        "test_dataset = to_map_style_dataset(test_iter)\n",
        "\n",
        "num_train = int(len(train_dataset) * 0.95)\n",
        "split_train_, split_valid_ = random_split(\n",
        "    train_dataset, [num_train, len(train_dataset) - num_train]\n",
        ")\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    split_train_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
        ")\n",
        "\n",
        "valid_dataloader = DataLoader(\n",
        "    split_valid_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
        ")\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "    test_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99qfij4G-OZS"
      },
      "outputs": [],
      "source": [
        "epoch_: int = None\n",
        "\n",
        "\n",
        "def train(dataloader):\n",
        "    model.train()\n",
        "    total_acc, total_count = 0, 0\n",
        "    log_interval = 500\n",
        "    start_time = time.time()\n",
        "\n",
        "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        predicted_label = model(text, offsets)\n",
        "        loss = criterion(predicted_label, label)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
        "        optimizer.step()\n",
        "        total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
        "        total_count += label.size(0)\n",
        "        if idx % log_interval == 0 and idx > 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            print(\n",
        "                '| epoch {:3d} | {:5d}/{:5d} batches '\n",
        "                '| accuracy {:8.3f}'.format(\n",
        "                    epoch, idx, len(dataloader), total_acc / total_count\n",
        "                )\n",
        "            )\n",
        "            total_acc, total_count = 0, 0\n",
        "            start_time = time.time()\n",
        "\n",
        "\n",
        "def evaluate(dataloader):\n",
        "    model.eval()\n",
        "    total_acc, total_count = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
        "            predicted_label = model(text, offsets)\n",
        "            loss = criterion(predicted_label, label)\n",
        "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
        "            total_count += label.size(0)\n",
        "\n",
        "    return total_acc / total_count\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cw430ju_-SuJ",
        "outputId": "be41fe77-54b1-472d-f916-538aa9b10082"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   1 |   500/ 1140 batches | accuracy    0.693\n",
            "| epoch   1 |  1000/ 1140 batches | accuracy    0.862\n",
            "| end of epoch   1 | time:  8.63s | valid accuracy    0.886\n",
            "-----------------------------------------------------------\n",
            "| epoch   2 |   500/ 1140 batches | accuracy    0.891\n",
            "| epoch   2 |  1000/ 1140 batches | accuracy    0.899\n",
            "| end of epoch   2 | time:  7.10s | valid accuracy    0.897\n",
            "-----------------------------------------------------------\n",
            "| epoch   3 |   500/ 1140 batches | accuracy    0.909\n",
            "| epoch   3 |  1000/ 1140 batches | accuracy    0.911\n",
            "| end of epoch   3 | time:  7.19s | valid accuracy    0.907\n",
            "-----------------------------------------------------------\n",
            "| epoch   4 |   500/ 1140 batches | accuracy    0.919\n",
            "| epoch   4 |  1000/ 1140 batches | accuracy    0.918\n",
            "| end of epoch   4 | time:  7.10s | valid accuracy    0.911\n",
            "-----------------------------------------------------------\n",
            "| epoch   5 |   500/ 1140 batches | accuracy    0.925\n",
            "| epoch   5 |  1000/ 1140 batches | accuracy    0.924\n",
            "| end of epoch   5 | time:  5.83s | valid accuracy    0.905\n",
            "-----------------------------------------------------------\n",
            "| epoch   6 |   500/ 1140 batches | accuracy    0.935\n",
            "| epoch   6 |  1000/ 1140 batches | accuracy    0.938\n",
            "| end of epoch   6 | time:  5.41s | valid accuracy    0.918\n",
            "-----------------------------------------------------------\n",
            "| epoch   7 |   500/ 1140 batches | accuracy    0.938\n",
            "| epoch   7 |  1000/ 1140 batches | accuracy    0.937\n",
            "| end of epoch   7 | time:  5.20s | valid accuracy    0.917\n",
            "-----------------------------------------------------------\n",
            "| epoch   8 |   500/ 1140 batches | accuracy    0.940\n",
            "| epoch   8 |  1000/ 1140 batches | accuracy    0.938\n",
            "| end of epoch   8 | time:  5.29s | valid accuracy    0.918\n",
            "-----------------------------------------------------------\n",
            "| epoch   9 |   500/ 1140 batches | accuracy    0.937\n",
            "| epoch   9 |  1000/ 1140 batches | accuracy    0.940\n",
            "| end of epoch   9 | time:  5.31s | valid accuracy    0.918\n",
            "-----------------------------------------------------------\n",
            "| epoch  10 |   500/ 1140 batches | accuracy    0.939\n",
            "| epoch  10 |  1000/ 1140 batches | accuracy    0.941\n",
            "| end of epoch  10 | time:  5.34s | valid accuracy    0.918\n",
            "-----------------------------------------------------------\n",
            "| epoch  11 |   500/ 1140 batches | accuracy    0.939\n",
            "| epoch  11 |  1000/ 1140 batches | accuracy    0.939\n",
            "| end of epoch  11 | time:  5.42s | valid accuracy    0.918\n",
            "-----------------------------------------------------------\n",
            "| epoch  12 |   500/ 1140 batches | accuracy    0.940\n",
            "| epoch  12 |  1000/ 1140 batches | accuracy    0.938\n",
            "| end of epoch  12 | time:  5.67s | valid accuracy    0.918\n",
            "-----------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(1, EPOCHS + 1):\n",
        "    epoch_start_time = time.time()\n",
        "    epoch_ = epoch\n",
        "    train(train_dataloader)\n",
        "    accu_val = evaluate(valid_dataloader)\n",
        "    if total_accu is not None and total_accu > accu_val:\n",
        "        scheduler.step()\n",
        "    else:\n",
        "        total_accu = accu_val\n",
        "\n",
        "    print(\n",
        "        '| end of epoch {:3d} | time: {:5.2f}s | '\n",
        "        'valid accuracy {:8.3f}'.format(epoch, time.time() - epoch_start_time, accu_val)\n",
        "    )\n",
        "    print('-' * 59)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cx7U_VSzXlLs"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checking the results of test dataset.\n",
            "test accuracy    0.906\n"
          ]
        }
      ],
      "source": [
        "print('Checking the results of test dataset.')\n",
        "accu_test = evaluate(test_dataloader)\n",
        "print('test accuracy {:8.3f}'.format(accu_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nhgxJsINXl17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This is a Sports news\n"
          ]
        }
      ],
      "source": [
        "IMDB_label_back = {0: \"neg\", 1: \"pos\"}\n",
        "\n",
        "\n",
        "def predict(text, text_pipeline):\n",
        "    with torch.no_grad():\n",
        "        text = torch.tensor(text_pipeline(text))\n",
        "        output = model(text, torch.tensor([0]))\n",
        "        return output.argmax(1).item() + 1\n",
        "\n",
        "\n",
        "ex_text_str = \"MEMPHIS, Tenn. – Four days ago, Jon Rahm was \\\n",
        "    enduring the season’s worst weather conditions on Sunday at The \\\n",
        "    Open on his way to a closing 75 at Royal Portrush, which \\\n",
        "    considering the wind and the rain was a respectable showing. \\\n",
        "    Thursday’s first round at the WGC-FedEx St. Jude Invitational \\\n",
        "    was another story. With temperatures in the mid-80s and hardly any \\\n",
        "    wind, the Spaniard was 13 strokes better in a flawless round. \\\n",
        "    Thanks to his best putting performance on the PGA Tour, Rahm \\\n",
        "    finished with an 8-under 62 for a three-stroke lead, which \\\n",
        "    was even more impressive considering he’d never played the \\\n",
        "    front nine at TPC Southwind.\"\n",
        "\n",
        "model = model.to('cpu')\n",
        "\n",
        "print(f\"This is a {IMDB_label_back[predict(ex_text_str, text_pipeline)]} mood\")\n",
        "\n",
        "en_text_str = \"\"\"I'm struggling to finish this\n",
        "\n",
        "I'm 6 episodes in and this series feels kind of off. Having read the comics, the characters don't seem like theyre the same personalities. It's very slow, and the dialogue is terrible. The only thing keeping me watching at this point is a hope that I can see more of the endless (especially delirium).\n",
        "Netflix should stay away from making anymore adaptations (especially after the cowboy bebop flop). I really think Gaiman made a mistake choosing Netflix, and I hope to live long enough to see another company remake it.\n",
        "Ill update my review if the show is any better once I finish.\"\"\"\n",
        "\n",
        "print(f\"This is a {IMDB_label_back[predict(ex_text_str, text_pipeline)]} mood\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Load_IMDB.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.13",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "e45d430dd4495a451adf3f96c36ab39ddd21d42ca8131a0e0d50ee113b976380"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
